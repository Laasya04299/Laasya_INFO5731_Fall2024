{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Laasya04299/Laasya_INFO5731_Fall2024/blob/main/Madige_Laasya_Exercise_02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DymRJbxDBCnf"
      },
      "source": [
        "# **INFO5731 In-class Exercise 2**\n",
        "\n",
        "The purpose of this exercise is to understand users' information needs, and then collect data from different sources for analysis by implementing web scraping using Python.\n",
        "\n",
        "**Expectations**:\n",
        "*   Students are expected to complete the exercise during lecture period to meet the active participation criteria of the course.\n",
        "*   Use the provided .*ipynb* document to write your code & respond to the questions. Avoid generating a new file.\n",
        "*   Write complete answers and run all the cells before submission.\n",
        "*   Make sure the submission is \"clean\"; *i.e.*, no unnecessary code cells.\n",
        "*   Once finished, allow shared rights from top right corner (*see Canvas for details*).\n",
        "\n",
        "**Total points**: 40\n",
        "\n",
        "**Deadline**: This in-class exercise is due at the end of the day tomorrow, at 11:59 PM.\n",
        "\n",
        "**Late submissions will have a penalty of 10% of the marks for each day of late submission. , and no requests will be answered. Manage your time accordingly.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FBKvD6O_TY6e"
      },
      "source": [
        "## Question 1 (10 Points)\n",
        "Describe an interesting research question (or practical question or something innovative) you have in mind, what kind of data should be collected to answer the question(s)? Specify the amount of data needed for analysis. Provide detailed steps for collecting and saving the data."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# write your answer here\n",
        "'''\n",
        "Research Question:\n",
        "How does the frequency of edits to Wikipedia articles correlate with their quality and relevance over time?\n",
        "\n",
        "Data Collection:\n",
        "Data Types Needed:\n",
        "  Article Metadata: Title, creation date, and last edited date.\n",
        "  Edit History: Number of edits, timestamps of edits and edit summaries.\n",
        "  Article Quality Metrics: Article assessments references and citations.\n",
        "Amount of Data:\n",
        "Number of Articles: A sample size of 1,000 to 5,000 articles\n",
        "Edit Records: The complete edit history for each article in the sample.\n",
        "Quality Assessments: Ratings or quality assessments for each article\n",
        "\n",
        "Steps for Collecting and Saving Data:\n",
        "Step 1: Define the Sample Set\n",
        "Choose a set of Wikipedia articles that are representative of different topics and quality levels.\n",
        "\n",
        "Step 2: Extract Article Metadata\n",
        "Use the Wikipedia API to extract metadata for each article, including titles, creation dates, and last edited dates.\n",
        "\n",
        "Step 3: Collect Edit History\n",
        "Retrieve the complete edit history for each article using the Wikipedia API.\n",
        "\n",
        "Step 4: Gather Article Quality Metrics\n",
        "Extract quality assessments from Wikipedia’s article assessment pages or using Wikipedia’s own datasets where available.\n",
        "\n",
        "Step 5: Store Data\n",
        "Save the extracted metadata, edit histories and quality metrics in a structured format such as JSON or CSV files.\n",
        "\n",
        "'''\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "JEj7H0eDeP4O",
        "outputId": "2e51e0fb-987c-46be-f65d-4a885fb1ab0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nResearch Question:\\nHow does the frequency of edits to Wikipedia articles correlate with their quality and relevance over time?\\n\\nData Collection:\\nData Types Needed:\\n  Article Metadata: Title, creation date, and last edited date.\\n  Edit History: Number of edits, timestamps of edits and edit summaries.\\n  Article Quality Metrics: Article assessments references and citations.\\nAmount of Data:\\nNumber of Articles: A sample size of 1,000 to 5,000 articles\\nEdit Records: The complete edit history for each article in the sample.\\nQuality Assessments: Ratings or quality assessments for each article\\n\\nSteps for Collecting and Saving Data:\\nStep 1: Define the Sample Set\\nChoose a set of Wikipedia articles that are representative of different topics and quality levels.\\n\\nStep 2: Extract Article Metadata\\nUse the Wikipedia API to extract metadata for each article, including titles, creation dates, and last edited dates.\\n\\nStep 3: Collect Edit History\\nRetrieve the complete edit history for each article using the Wikipedia API.\\n\\nStep 4: Gather Article Quality Metrics\\nExtract quality assessments from Wikipedia’s article assessment pages or using Wikipedia’s own datasets where available.\\n\\nStep 5: Store Data\\nSave the extracted metadata, edit histories and quality metrics in a structured format such as JSON or CSV files.\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9RqrlwdTfvl"
      },
      "source": [
        "## Question 2 (10 Points)\n",
        "Write Python code to collect a dataset of 1000 samples related to the question discussed in Question 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4XvRknixTh1g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "760ee25d-ced5-413d-b00b-3026749ec5db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetching data for article 1/1000: User talk:Clareiet\n",
            "Fetching data for article 2/1000: User talk:Xx*MCR-ROX*xX\n",
            "Fetching data for article 3/1000: User talk:Lilone12~enwiki\n",
            "Fetching data for article 4/1000: User talk:KanziGG\n",
            "Fetching data for article 5/1000: Category:Mobile phone companies of Bosnia and Herzegovina\n",
            "Fetching data for article 6/1000: User talk:2601:2C4:C800:E3B0:BC23:D059:C44E:7DB8\n",
            "Fetching data for article 7/1000: User:Wellboyswhatsthecraic/TWA/Earth/2\n",
            "Fetching data for article 8/1000: User talk:68.197.19.122\n",
            "Fetching data for article 9/1000: Aeroflot Flight 3603\n",
            "Fetching data for article 10/1000: Yardea\n",
            "Fetching data for article 11/1000: Toby Radford\n",
            "Fetching data for article 12/1000: User talk:58.106.239.195\n",
            "Fetching data for article 13/1000: Talk:Fred C. Ainsworth\n",
            "Fetching data for article 14/1000: Talk:Individual Paralympic Athletes\n",
            "Fetching data for article 15/1000: User talk:106.66.121.244\n",
            "Fetching data for article 16/1000: User talk:68.38.131.22\n",
            "Fetching data for article 17/1000: User talk:217.116.54.98\n",
            "Fetching data for article 18/1000: User talk:172.88.50.107\n",
            "Fetching data for article 19/1000: User talk:Hisham Mirsa M\n",
            "Fetching data for article 20/1000: Talk:Campagne de France (1944)\n",
            "Fetching data for article 21/1000: File:Z-related hexachords from Wozzeck.png\n",
            "Fetching data for article 22/1000: Talk:Normanellidae\n",
            "Fetching data for article 23/1000: Japanese clans\n",
            "Fetching data for article 24/1000: Lindsay James\n",
            "Fetching data for article 25/1000: Talk:Kevin Newman (baseball)\n",
            "Fetching data for article 26/1000: Space Pirates (video game)\n",
            "Fetching data for article 27/1000: User talk:Gude~enwiki\n",
            "Fetching data for article 28/1000: User:Dmurthy\n",
            "Fetching data for article 29/1000: Talk:Gikongoro\n",
            "Fetching data for article 30/1000: File talk:Wickiana5.jpg\n",
            "Fetching data for article 31/1000: User talk:Jessemilby\n",
            "Fetching data for article 32/1000: User talk:99.21.250.180\n",
            "Fetching data for article 33/1000: James C. Donnelly\n",
            "Fetching data for article 34/1000: Talk:The Real Housewives of Vancouver\n",
            "Fetching data for article 35/1000: User talk:76.177.163.74\n",
            "Fetching data for article 36/1000: Fehl-Ritzhausen\n",
            "Fetching data for article 37/1000: User talk:210.215.151.70\n",
            "Fetching data for article 38/1000: User talk:98.253.10.247\n",
            "Fetching data for article 39/1000: Sheena Rose\n",
            "Fetching data for article 40/1000: List of players with a 2017 PDC Tour Card\n",
            "Fetching data for article 41/1000: User:Frigotoni/Icongallery\n",
            "Fetching data for article 42/1000: User talk:65.60.240.53\n",
            "Fetching data for article 43/1000: User talk:2804:14D:32A0:26C2:6CDB:D6DF:DB85:1256\n",
            "Fetching data for article 44/1000: Category talk:Sleeping in the Aviary albums\n",
            "Fetching data for article 45/1000: File:The Chaos Chapter - Fight or Escape.jpg\n",
            "Fetching data for article 46/1000: Category talk:1967 in Indian politics\n",
            "Fetching data for article 47/1000: Talk:1940 Richmond Spiders football team\n",
            "Fetching data for article 48/1000: User talk:Stantongroupinc\n",
            "Fetching data for article 49/1000: Talk:Amy B. Mitchell House\n",
            "Fetching data for article 50/1000: Talk:To the Edge of the Earth/GA1\n",
            "Fetching data for article 51/1000: Tripura Public Works Department\n",
            "Fetching data for article 52/1000: Template talk:Iso/V/text\n",
            "Fetching data for article 53/1000: 1990 Diet Pepsi Championships\n",
            "Fetching data for article 54/1000: Grandma Moses American Primitive\n",
            "Fetching data for article 55/1000: User:Dp76764/monobook.js/script.js\n",
            "Fetching data for article 56/1000: Talk:Los Tiempos\n",
            "Fetching data for article 57/1000: Namchö Mingyur Dorje\n",
            "Fetching data for article 58/1000: User talk:2A02:C7C:DD8B:7400:CC98:A919:5585:31CD\n",
            "Fetching data for article 59/1000: User talk:2601:18E:C501:678B:5112:35B1:6CA8:2EE2\n",
            "Fetching data for article 60/1000: User talk:Jordanfallis6\n",
            "Fetching data for article 61/1000: User talk:2405:205:4285:59FE:0:0:33E:B8A1\n",
            "Fetching data for article 62/1000: User talk:121.45.68.43\n",
            "Fetching data for article 63/1000: User talk:142.60.14.102\n",
            "Fetching data for article 64/1000: Category:Buildings and structures in Lincoln County, Idaho\n",
            "Fetching data for article 65/1000: User talk:24.192.94.214\n",
            "Fetching data for article 66/1000: User talk:68.60.36.121\n",
            "Fetching data for article 67/1000: User talk:82.27.254.251\n",
            "Fetching data for article 68/1000: John Malet\n",
            "Fetching data for article 69/1000: User talk:Boss65~enwiki\n",
            "Fetching data for article 70/1000: Talk:Charles Joseph Alleyn\n",
            "Fetching data for article 71/1000: User talk:Donflori/sandbox\n",
            "Fetching data for article 72/1000: Talk:Multicentric carpotarsal osteolysis syndrome\n",
            "Fetching data for article 73/1000: Talk:Mo Elleithee\n",
            "Fetching data for article 74/1000: File:Dotmocracy sheet example es.jpg\n",
            "Fetching data for article 75/1000: User talk:74.13.126.77\n",
            "Fetching data for article 76/1000: User talk:2405:201:C002:4826:5D23:B7B9:9C69:6BE0\n",
            "Fetching data for article 77/1000: Talk:Jack Walker (rugby union)\n",
            "Fetching data for article 78/1000: User talk:67.6.6.56\n",
            "Fetching data for article 79/1000: User talk:Bkshs\n",
            "Fetching data for article 80/1000: Template:Taxonomy/Phycodinae\n",
            "Fetching data for article 81/1000: Category:Communities of China\n",
            "Fetching data for article 82/1000: User talk:Ifixapplecare\n",
            "Fetching data for article 83/1000: File talk:Valerian and the City of a Thousand Planets.jpg\n",
            "Fetching data for article 84/1000: Bhagavath Singh\n",
            "Fetching data for article 85/1000: Category talk:Geography of Casey County, Kentucky\n",
            "Fetching data for article 86/1000: User talk:124.148.45.208\n",
            "Fetching data for article 87/1000: Template talk:Clown-class gunboat\n",
            "Fetching data for article 88/1000: Category:Toulouse FC templates\n",
            "Fetching data for article 89/1000: User talk:Shokofujita0518/sandbox\n",
            "Fetching data for article 90/1000: Category talk:Yirrmal songs\n",
            "Fetching data for article 91/1000: User talk:Kodybartlett\n",
            "Fetching data for article 92/1000: Caudron Type B\n",
            "Fetching data for article 93/1000: User:Robinstar1989\n",
            "Fetching data for article 94/1000: User talk:67.170.62.74\n",
            "Fetching data for article 95/1000: Talk:Mark Coughlan\n",
            "Fetching data for article 96/1000: User talk:Denrik2093\n",
            "Fetching data for article 97/1000: Talk:Biate (town)\n",
            "Fetching data for article 98/1000: Talk:Winter and Summer\n",
            "Fetching data for article 99/1000: User talk:101.113.44.45\n",
            "Fetching data for article 100/1000: User:Yungur\n",
            "Fetching data for article 101/1000: Baglioni family\n",
            "Fetching data for article 102/1000: Wikipedia:Sockpuppet investigations/Mohamed Eldakak\n",
            "Fetching data for article 103/1000: User talk:Davidmccarthyconsulting\n",
            "Fetching data for article 104/1000: User talk:65.18.68.219\n",
            "Fetching data for article 105/1000: Category:Akrotiri and Dhekelia people\n",
            "Fetching data for article 106/1000: Talk:Gmina Ciężkowice\n",
            "Fetching data for article 107/1000: Category:1975 in New Caledonia\n",
            "Fetching data for article 108/1000: User talk:80.195.62.24\n",
            "Fetching data for article 109/1000: List of Tibetan writers\n",
            "Fetching data for article 110/1000: Hadeel Abdel Aziz\n",
            "Fetching data for article 111/1000: User talk:128.194.42.169\n",
            "Fetching data for article 112/1000: User talk:Erik P. Bethel\n",
            "Fetching data for article 113/1000: User talk:Skibiditoilet111\n",
            "Fetching data for article 114/1000: User talk:Timyan~enwiki\n",
            "Fetching data for article 115/1000: Talk:Hayranlar, Mengen\n",
            "Fetching data for article 116/1000: Willard G. Smith\n",
            "Fetching data for article 117/1000: File:Live and Learn Joe Public.jpg\n",
            "Fetching data for article 118/1000: Talk:Ole Miss Rebels/Archive 1\n",
            "Fetching data for article 119/1000: User talk:98.226.163.105\n",
            "Fetching data for article 120/1000: User talk:Ahmetuyar\n",
            "Fetching data for article 121/1000: User talk:2406:7400:63:D939:4129:B11F:CEA2:A402\n",
            "Fetching data for article 122/1000: Talk:Burstsort\n",
            "Fetching data for article 123/1000: User talk:72.222.143.142\n",
            "Fetching data for article 124/1000: User:Mintylimes\n",
            "Fetching data for article 125/1000: Talk:Maree Kennedy\n",
            "Fetching data for article 126/1000: Talk:Jean-Marc Piotte\n",
            "Fetching data for article 127/1000: Category talk:Walking simulators\n",
            "Fetching data for article 128/1000: User talk:Justdidier~enwiki\n",
            "Fetching data for article 129/1000: Swiss Maid\n",
            "Fetching data for article 130/1000: User talk:Ohconfucius/dashes.js\n",
            "Fetching data for article 131/1000: User:Roychang\n",
            "Fetching data for article 132/1000: User talk:68.199.105.183\n",
            "Fetching data for article 133/1000: Template:PD-ineligible\n",
            "Fetching data for article 134/1000: Eremiaphila reticulata\n",
            "Fetching data for article 135/1000: User talk:86.171.182.232\n",
            "Fetching data for article 136/1000: User talk:Avalonthas\n",
            "Fetching data for article 137/1000: Netherlands at the 1936 Winter Olympics\n",
            "Fetching data for article 138/1000: User talk:TheStonehouseBand\n",
            "Fetching data for article 139/1000: User talk:81.108.165.77\n",
            "Fetching data for article 140/1000: User talk:2405:201:5009:3040:608C:F9A4:8DA9:D191\n",
            "Fetching data for article 141/1000: Selected Poems (Pinsky collection)\n",
            "Fetching data for article 142/1000: Wikipedia:Articles for deletion/Katherine Lester\n",
            "Fetching data for article 143/1000: Talk:Bani Awf\n",
            "Fetching data for article 144/1000: User:BBC Playhouse History\n",
            "Fetching data for article 145/1000: User talk:5.112.187.193\n",
            "Fetching data for article 146/1000: Template:Celtic F.C. Player of the Year\n",
            "Fetching data for article 147/1000: User:Musicgarden\n",
            "Fetching data for article 148/1000: User talk:72.219.214.166\n",
            "Fetching data for article 149/1000: John Sanderson (cricketer)\n",
            "Fetching data for article 150/1000: Death's Mannikins\n",
            "Fetching data for article 151/1000: Category:Education ministers of the Dominican Republic\n",
            "Fetching data for article 152/1000: User talk:75.12.152.157\n",
            "Fetching data for article 153/1000: File:Jack White - Hi-De-Ho.png\n",
            "Fetching data for article 154/1000: User talk:Antonio Parigi\n",
            "Fetching data for article 155/1000: Talk:José Edvar Simões\n",
            "Fetching data for article 156/1000: Template:Data missing/sandbox\n",
            "Fetching data for article 157/1000: Category talk:Structure of contemporary armies\n",
            "Fetching data for article 158/1000: User talk:MrDarcy/Jan to Nov 2005\n",
            "Fetching data for article 159/1000: Category:2016 crimes in Africa\n",
            "Fetching data for article 160/1000: User talk:Buddy07~enwiki\n",
            "Fetching data for article 161/1000: Category talk:Christian organizations established in 2016\n",
            "Fetching data for article 162/1000: User talk:70.241.127.183\n",
            "Fetching data for article 163/1000: Charles Geerts (businessman)\n",
            "Fetching data for article 164/1000: User talk:92.96.68.144\n",
            "Fetching data for article 165/1000: User talk:Rayjoseph23\n",
            "Fetching data for article 166/1000: Talk:Hot Pink (album)/GA2\n",
            "Fetching data for article 167/1000: Category:1935–36 in Italian football leagues\n",
            "Fetching data for article 168/1000: Category talk:Wildstorm imprint covers\n",
            "Fetching data for article 169/1000: Kalina, West Pomeranian Voivodeship\n",
            "Fetching data for article 170/1000: Category talk:1830s disasters in Ireland\n",
            "Fetching data for article 171/1000: Wikipedia:WikiProject Military history/News/June 2019/Project news\n",
            "Fetching data for article 172/1000: User talk:87.110.103.40\n",
            "Fetching data for article 173/1000: User:Huusmik\n",
            "Fetching data for article 174/1000: User talk:Sbihmkolkata\n",
            "Fetching data for article 175/1000: The Shedd Institute\n",
            "Fetching data for article 176/1000: User talk:166.249.201.88\n",
            "Fetching data for article 177/1000: User talk:85.238.99.104\n",
            "Fetching data for article 178/1000: User talk:213.175.165.198\n",
            "Fetching data for article 179/1000: Wikipedia:WikiProject Spam/LinkReports/taiwancinema.blogspot.tw\n",
            "Fetching data for article 180/1000: File talk:FirstAndLastThingsHGWells.jpg\n",
            "Fetching data for article 181/1000: Category talk:Radio programs adapted into television shows\n",
            "Fetching data for article 182/1000: Talk:Matter of Time (Axium album)\n",
            "Fetching data for article 183/1000: 2012–13 Liga Alef\n",
            "Fetching data for article 184/1000: Category talk:Shipwrecks in the Irish Sea\n",
            "Fetching data for article 185/1000: Talk:Wanbu Huayanjing Pagoda\n",
            "Fetching data for article 186/1000: User talk:Peter1429\n",
            "Fetching data for article 187/1000: Talk:Edward Acton (academic)\n",
            "Fetching data for article 188/1000: User talk:TheresNoTime/Mental health\n",
            "Fetching data for article 189/1000: Talk:Marville, Meuse\n",
            "Fetching data for article 190/1000: User talk:Welovedarien\n",
            "Fetching data for article 191/1000: User talk:82.12.219.215\n",
            "Fetching data for article 192/1000: Wikipedia:Articles for deletion/Pamela E. Swett\n",
            "Fetching data for article 193/1000: Talk:Bretel butter\n",
            "Fetching data for article 194/1000: Talk:Sugar Babies (musical)\n",
            "Fetching data for article 195/1000: Pyrausta haemapastalis\n",
            "Fetching data for article 196/1000: User talk:Thebolt3\n",
            "Fetching data for article 197/1000: User talk:Weapontactical\n",
            "Fetching data for article 198/1000: User talk:Martality\n",
            "Fetching data for article 199/1000: Robin Ling\n",
            "Fetching data for article 200/1000: File talk:Alexander-ONeal-Sunshine--Rain-22726.jpg\n",
            "Fetching data for article 201/1000: User talk:Kyesac\n",
            "Fetching data for article 202/1000: User talk:24.98.107.221\n",
            "Fetching data for article 203/1000: Category:Cycling in Kazakhstan\n",
            "Fetching data for article 204/1000: Talk:James Gaffigan (conductor)\n",
            "Fetching data for article 205/1000: File talk:HELLO LOVERS cover.jpg\n",
            "Fetching data for article 206/1000: File talk:Collectionpaul.jpg\n",
            "Fetching data for article 207/1000: Yenikonak, Elâzığ\n",
            "Fetching data for article 208/1000: User:Uooskie\n",
            "Fetching data for article 209/1000: File talk:PisIscCassette.jpg\n",
            "Fetching data for article 210/1000: User talk:42.106.72.215\n",
            "Fetching data for article 211/1000: User talk:122.60.74.242\n",
            "Fetching data for article 212/1000: User talk:Upananda roy\n",
            "Fetching data for article 213/1000: User talk:110.136.241.62\n",
            "Fetching data for article 214/1000: User talk:Pdaddy69353\n",
            "Fetching data for article 215/1000: Talk:Peraglyphis crustata\n",
            "Fetching data for article 216/1000: Talk:Prostitution in Vanuatu\n",
            "Fetching data for article 217/1000: Wikipedia:Articles for deletion/Fowler Middle School (second nomination)\n",
            "Fetching data for article 218/1000: User talk:2603:7080:6600:C66E:8D10:D9EB:B021:8B14\n",
            "Fetching data for article 219/1000: User:Jdenijs/Books/Radar AWACS\n",
            "Fetching data for article 220/1000: User talk:86.173.199.43\n",
            "Fetching data for article 221/1000: User talk:27.7.71.209\n",
            "Fetching data for article 222/1000: User talk:Wikisprávce Beeswax\n",
            "Fetching data for article 223/1000: User talk:69.85.105.210\n",
            "Fetching data for article 224/1000: User talk:Mrs.Kaulitz23\n",
            "Fetching data for article 225/1000: Wikipedia talk:WikiProject Architecture/Members\n",
            "Fetching data for article 226/1000: Port Clarence (disambiguation)\n",
            "Fetching data for article 227/1000: The Last of the Mohicans (1932 serial)\n",
            "Fetching data for article 228/1000: User talk:134.219.176.114\n",
            "Fetching data for article 229/1000: Talk:AMR radiotelephone network (Czechoslovakia)\n",
            "Fetching data for article 230/1000: Talk:We Are All Murderers\n",
            "Fetching data for article 231/1000: User:Jai Singh Jhala\n",
            "Fetching data for article 232/1000: Talk:Ümit Cizre\n",
            "Fetching data for article 233/1000: User talk:12.216.109.82\n",
            "Fetching data for article 234/1000: File:Rupe Tomay Bholabo Na poster.gif\n",
            "Fetching data for article 235/1000: Arthur Peters (Australian cricketer)\n",
            "Fetching data for article 236/1000: Talk:Mallow-Tralee line\n",
            "Fetching data for article 237/1000: The Surprise Party (Smash)\n",
            "Fetching data for article 238/1000: User:DON'T DAWB THAT PASTEY SCAT!\n",
            "Fetching data for article 239/1000: Category talk:Music venues in Washington (state)\n",
            "Fetching data for article 240/1000: Humanitarian impact of the Russo-Georgian War\n",
            "Fetching data for article 241/1000: Talk:Alessandro Bisolti\n",
            "Fetching data for article 242/1000: Wikipedia:Files for upload/January 2011\n",
            "Fetching data for article 243/1000: Template:England-cricket-bio-1990s-stub\n",
            "Fetching data for article 244/1000: User talk:101.178.171.197\n",
            "Fetching data for article 245/1000: User talk:189.139.3.78\n",
            "Fetching data for article 246/1000: User:Ajraymond/TricotMachine\n",
            "Fetching data for article 247/1000: Category:Wikipedia sockpuppets of DavId Troia\n",
            "Fetching data for article 248/1000: User talk:62.205.123.124\n",
            "Fetching data for article 249/1000: User talk:213.66.62.229\n",
            "Fetching data for article 250/1000: Template talk:1924 New Zealand Olympic team\n",
            "Fetching data for article 251/1000: User:Bhoyet31\n",
            "Fetching data for article 252/1000: User talk:2601:18D:8800:7059:A567:53A0:4955:93F3\n",
            "Fetching data for article 253/1000: Wikipedia talk:WikiProject Japan/Project talk\n",
            "Fetching data for article 254/1000: User talk:Orhan anac\n",
            "Fetching data for article 255/1000: Template talk:Taxonomy/Eriomastyx\n",
            "Fetching data for article 256/1000: Talk:Grace Deeb\n",
            "Fetching data for article 257/1000: User talk:2402:8100:391B:9D1E:B4EF:4B2B:CF63:8337\n",
            "Fetching data for article 258/1000: 1983 Illinois Fighting Illini football team\n",
            "Fetching data for article 259/1000: User talk:86.148.67.189\n",
            "Fetching data for article 260/1000: User talk:Cool boi is very cool\n",
            "Fetching data for article 261/1000: Category talk:1990s establishments in Iran\n",
            "Fetching data for article 262/1000: Wikipedia:Selected anniversaries/March 22\n",
            "Fetching data for article 263/1000: User talk:HotGurl1995\n",
            "Fetching data for article 264/1000: Baiji SC\n",
            "Fetching data for article 265/1000: Talk:Polyporus ciliatus\n",
            "Fetching data for article 266/1000: Template talk:Mountfield HK roster\n",
            "Fetching data for article 267/1000: Talk:Achatinella buddii\n",
            "Fetching data for article 268/1000: User talk:Jeduxbury\n",
            "Fetching data for article 269/1000: User talk:2A02:587:8027:F300:BCB0:764:359B:9B26\n",
            "Fetching data for article 270/1000: Death of Manon Dubé\n",
            "Fetching data for article 271/1000: Talk:Kpandai\n",
            "Fetching data for article 272/1000: User:ThumbButte\n",
            "Fetching data for article 273/1000: User talk:Antonio Torres Ramos Jr\n",
            "Fetching data for article 274/1000: User talk:Zezey\n",
            "Fetching data for article 275/1000: AubieSat-1\n",
            "Fetching data for article 276/1000: Template talk:River item line\n",
            "Fetching data for article 277/1000: Talk:Canton Township, Fillmore County, Minnesota\n",
            "Fetching data for article 278/1000: Talk:County Road 76 (Chisago County, Minnesota)\n",
            "Fetching data for article 279/1000: User talk:Trinity-marketing\n",
            "Fetching data for article 280/1000: Tridactylus\n",
            "Fetching data for article 281/1000: User talk:81.109.30.155\n",
            "Fetching data for article 282/1000: Wikipedia:Articles for deletion/Lalrampana Pauta\n",
            "Fetching data for article 283/1000: User talk:2600:1009:B04F:8D75:6DD7:3A10:8A29:684B\n",
            "Fetching data for article 284/1000: Talk:WEC 24\n",
            "Fetching data for article 285/1000: User talk:104.205.91.237\n",
            "Fetching data for article 286/1000: User:DraculavanHelsing/Books/Hussite Wars\n",
            "Fetching data for article 287/1000: User talk:209.141.206.214\n",
            "Fetching data for article 288/1000: User talk:200.164.31.2\n",
            "Fetching data for article 289/1000: User talk:62.253.26.56\n",
            "Fetching data for article 290/1000: User talk:Ebrooney\n",
            "Fetching data for article 291/1000: Talk:The Alternative Museum\n",
            "Fetching data for article 292/1000: User:Justinceballos/sandbox\n",
            "Fetching data for article 293/1000: Nor'easter\n",
            "Fetching data for article 294/1000: User talk:2607:FEA8:2D5F:F322:CCF9:878E:A257:5159\n",
            "Fetching data for article 295/1000: Talk:Flux (board game)\n",
            "Fetching data for article 296/1000: Talk:Lee Yu-bin\n",
            "Fetching data for article 297/1000: User:InverseHypercube/agnostic atheist\n",
            "Fetching data for article 298/1000: User:Acampos716\n",
            "Fetching data for article 299/1000: Talk:Mikey O'Reilly\n",
            "Fetching data for article 300/1000: User talk:Deirdredanaher\n",
            "Fetching data for article 301/1000: User talk:Riseupconsultancy\n",
            "Fetching data for article 302/1000: File:Marble Arch Mound staircase.jpg\n",
            "Fetching data for article 303/1000: Rolf Harris Cartoon Time\n",
            "Fetching data for article 304/1000: User talk:107.77.228.149\n",
            "Fetching data for article 305/1000: User:ClueBot III/Detailed Indices/User talk:Charlesdrakew/Archives/2011/October\n",
            "Fetching data for article 306/1000: User talk:70.54.27.228\n",
            "Fetching data for article 307/1000: User talk:Thetranspantaco\n",
            "Fetching data for article 308/1000: Grid-style social management in China\n",
            "Fetching data for article 309/1000: User talk:90.222.99.23\n",
            "Fetching data for article 310/1000: User talk:TrollerDeezNutz69\n",
            "Fetching data for article 311/1000: User talk:71.49.84.208\n",
            "Fetching data for article 312/1000: User talk:2603:9000:DA0A:1700:8C2B:C9D8:455A:AFF2\n",
            "Fetching data for article 313/1000: File talk:Intifada – The Long Day of Rage book cover.jpg\n",
            "Fetching data for article 314/1000: User talk:Annakul\n",
            "Fetching data for article 315/1000: User talk:Dipendra basnet\n",
            "Fetching data for article 316/1000: User talk:Aarkayne\n",
            "Fetching data for article 317/1000: User talk:68.50.105.189\n",
            "Fetching data for article 318/1000: Category talk:Films shot at Cité du Cinéma\n",
            "Fetching data for article 319/1000: Category talk:1998–99 in English women's football\n",
            "Fetching data for article 320/1000: 2021 AIBA Youth World Boxing Championships\n",
            "Fetching data for article 321/1000: User:Neangar\n",
            "Fetching data for article 322/1000: User:L'Aquatique/Userboxes/KPC\n",
            "Fetching data for article 323/1000: Talk:Mezzofanti\n",
            "Fetching data for article 324/1000: User talk:89.102.139.225\n",
            "Fetching data for article 325/1000: Talk:Pinchas ben Yair\n",
            "Fetching data for article 326/1000: User talk:RohanPRohit\n",
            "Fetching data for article 327/1000: User talk:81.10.10.183\n",
            "Fetching data for article 328/1000: Agostino Pinelli Ardimenti\n",
            "Fetching data for article 329/1000: Hoylake Urban District\n",
            "Fetching data for article 330/1000: User talk:2604:1500:8011:3800:B19D:7C8B:78:F081\n",
            "Fetching data for article 331/1000: User talk:184.175.49.98\n",
            "Fetching data for article 332/1000: War (Henry Cow song)\n",
            "Fetching data for article 333/1000: User talk:173.52.246.74\n",
            "Fetching data for article 334/1000: Category talk:1980 in Moscow\n",
            "Fetching data for article 335/1000: Talk:Water motorsports at the 1908 Summer Olympics\n",
            "Fetching data for article 336/1000: User talk:68.13.101.162\n",
            "Fetching data for article 337/1000: User talk:168.156.208.1\n",
            "Fetching data for article 338/1000: Category:University of California, San Francisco\n",
            "Fetching data for article 339/1000: Talk:2020 Australian Capital Territory general election\n",
            "Fetching data for article 340/1000: Dos Pilas\n",
            "Fetching data for article 341/1000: Talk:Mount Myohyang\n",
            "Fetching data for article 342/1000: File talk:Completely phils.jpg\n",
            "Fetching data for article 343/1000: User talk:Yahnozha\n",
            "Fetching data for article 344/1000: User talk:124.168.205.105\n",
            "Fetching data for article 345/1000: User talk:63.200.125.254\n",
            "Fetching data for article 346/1000: Template:Centurynum/n\n",
            "Fetching data for article 347/1000: Wikipedia:Articles for deletion/Artificial artificial intelligence\n",
            "Fetching data for article 348/1000: Roland Surrugue\n",
            "Fetching data for article 349/1000: Bud Estes\n",
            "Fetching data for article 350/1000: Category:Wikipedia articles without plot summaries from November 2014\n",
            "Fetching data for article 351/1000: User talk:Ssviator\n",
            "Fetching data for article 352/1000: User talk:Techinvolv\n",
            "Fetching data for article 353/1000: Talk:Guilty as Charged (Cock Sparrer album)\n",
            "Fetching data for article 354/1000: File:Bcconservatives-logo.jpg\n",
            "Fetching data for article 355/1000: Julius La Rosa\n",
            "Fetching data for article 356/1000: Category:Works by Bruce Jay Friedman\n",
            "Fetching data for article 357/1000: User talk:122.174.215.56\n",
            "Fetching data for article 358/1000: Category:1896 in international relations\n",
            "Fetching data for article 359/1000: Category talk:Church of England church buildings in the London Borough of Havering\n",
            "Fetching data for article 360/1000: User talk:AdamSmith~enwiki\n",
            "Fetching data for article 361/1000: User talk:128.120.111.186\n",
            "Fetching data for article 362/1000: User talk:El kebir twita\n",
            "Fetching data for article 363/1000: Category talk:Red Rodney albums\n",
            "Fetching data for article 364/1000: Talk:Adrian Utley\n",
            "Fetching data for article 365/1000: User talk:Boombaggy101\n",
            "Fetching data for article 366/1000: User:Morenooso/Stanley Rother working\n",
            "Fetching data for article 367/1000: Harry Glover (rugby union)\n",
            "Fetching data for article 368/1000: User talk:Johnshaughnessy\n",
            "Fetching data for article 369/1000: Category:EC 7.6.2\n",
            "Fetching data for article 370/1000: User talk:2600:8805:C488:3A00:409:2DE9:F58F:A3FF\n",
            "Fetching data for article 371/1000: Talk:Shining Energy\n",
            "Fetching data for article 372/1000: User:Haverly999\n",
            "Fetching data for article 373/1000: Wikipedia:Wikipedia Signpost/2007-12-10/Arbitration report\n",
            "Fetching data for article 374/1000: User talk:96.4.21.75\n",
            "Fetching data for article 375/1000: Category talk:Deaths from lung cancer in Turkey\n",
            "Fetching data for article 376/1000: Hybrid iguana\n",
            "Fetching data for article 377/1000: User:86.152.107.49\n",
            "Fetching data for article 378/1000: Talk:The Old Scoundrel\n",
            "Fetching data for article 379/1000: User talk:Hrafeiro\n",
            "Fetching data for article 380/1000: Talk:The Heroes (2008 TV series)\n",
            "Fetching data for article 381/1000: User talk:69.146.2.40\n",
            "Fetching data for article 382/1000: User talk:69.177.214.220\n",
            "Fetching data for article 383/1000: User talk:Trucksforyou123\n",
            "Fetching data for article 384/1000: User talk:124.191.88.150\n",
            "Fetching data for article 385/1000: User talk:37.6.183.94\n",
            "Fetching data for article 386/1000: User talk:Caprjournalism\n",
            "Fetching data for article 387/1000: User talk:Digital training india\n",
            "Fetching data for article 388/1000: User:Arwyan Poudel/sandbox\n",
            "Fetching data for article 389/1000: User talk:86.165.144.132\n",
            "Fetching data for article 390/1000: Talk:Platopsomyia\n",
            "Fetching data for article 391/1000: User talk:31.54.110.89\n",
            "Fetching data for article 392/1000: User:JackDB11\n",
            "Fetching data for article 393/1000: Category:Malvinas Argentinas Partido\n",
            "Fetching data for article 394/1000: User talk:122.172.48.4\n",
            "Fetching data for article 395/1000: Wikipedia:Articles for deletion/List of most populous provinces in Peru\n",
            "Fetching data for article 396/1000: User talk:Fabryce~enwiki\n",
            "Fetching data for article 397/1000: User talk:71.237.225.80\n",
            "Fetching data for article 398/1000: Category talk:Human rights in Kuwait\n",
            "Fetching data for article 399/1000: Talk:Punchbowl, New South Wales\n",
            "Fetching data for article 400/1000: File:Rocket science album.jpg\n",
            "Fetching data for article 401/1000: User talk:117.202.105.95\n",
            "Fetching data for article 402/1000: User talk:5.90.128.22\n",
            "Fetching data for article 403/1000: Anthony van Ryneveld\n",
            "Fetching data for article 404/1000: User talk:72.204.132.42\n",
            "Fetching data for article 405/1000: Beck: The Eye of the Storm\n",
            "Fetching data for article 406/1000: Alan Hinde\n",
            "Fetching data for article 407/1000: File:Mount Allison University Logo.svg\n",
            "Fetching data for article 408/1000: Talk:VSI Tampa Bay FC (W-League)\n",
            "Fetching data for article 409/1000: File:Instituto de investigaciones ambientales del pacífico (logo).png\n",
            "Fetching data for article 410/1000: User talk:Joselyn108\n",
            "Fetching data for article 411/1000: 1981 Barbadian general election\n",
            "Fetching data for article 412/1000: Category talk:Suicide bombing by continent\n",
            "Fetching data for article 413/1000: User talk:Miguel23T\n",
            "Fetching data for article 414/1000: User talk:Adam280494\n",
            "Fetching data for article 415/1000: User talk:Ochomari\n",
            "Fetching data for article 416/1000: User talk:Lizziebathory\n",
            "Fetching data for article 417/1000: User:Firebowl99\n",
            "Fetching data for article 418/1000: Template talk:Bulgaria-tv-station-stub\n",
            "Fetching data for article 419/1000: User talk:Zmicklea\n",
            "Fetching data for article 420/1000: User:Ashleygreenfield\n",
            "Fetching data for article 421/1000: User talk:76.79.51.230\n",
            "Fetching data for article 422/1000: Richard Fantl\n",
            "Fetching data for article 423/1000: Tecla San Andres Ziga\n",
            "Fetching data for article 424/1000: User talk:92.40.165.73\n",
            "Fetching data for article 425/1000: Talk:Miss Universe Germany 2017\n",
            "Fetching data for article 426/1000: User:AARUPADAI VEEDU INSTITUTE OF TECHNOLOGY/sandbox\n",
            "Fetching data for article 427/1000: Talk:Asavari (thaat)\n",
            "Fetching data for article 428/1000: Talk:Steven Trout\n",
            "Fetching data for article 429/1000: 2020 Sri Lankan parliamentary election\n",
            "Fetching data for article 430/1000: Category:Buses by country\n",
            "Fetching data for article 431/1000: User talk:2409:4060:284:C35C:4583:7568:CFA0:382C\n",
            "Fetching data for article 432/1000: Talk:John Robert Holland\n",
            "Fetching data for article 433/1000: User talk:82.3.57.122\n",
            "Fetching data for article 434/1000: User talk:78.60.103.71\n",
            "Fetching data for article 435/1000: User talk:68.51.208.36\n",
            "Fetching data for article 436/1000: File:Enyaceltssingle.jpg\n",
            "Fetching data for article 437/1000: File talk:The Complete Far Side.jpg\n",
            "Fetching data for article 438/1000: User talk:BIGBOIS69\n",
            "Fetching data for article 439/1000: User talk:JoJMasterRace\n",
            "Fetching data for article 440/1000: Greg Jennings\n",
            "Fetching data for article 441/1000: 1911 Bootle by-election\n",
            "Fetching data for article 442/1000: User talk:AliHossain33\n",
            "Fetching data for article 443/1000: Category talk:B-Class Russia (technology and engineering) articles\n",
            "Fetching data for article 444/1000: Category:Wikipedia files with Korean-language subtitles\n",
            "Fetching data for article 445/1000: User talk:Hcdhgdjhgyj\n",
            "Fetching data for article 446/1000: Talk:Vsya Moskva\n",
            "Fetching data for article 447/1000: User talk:JamesR/TalkArchive/2021/March\n",
            "Fetching data for article 448/1000: Wikipedia talk:WikiProject Women in Red/Missing articles by time period/1900-1909\n",
            "Fetching data for article 449/1000: User talk:117.203.144.231\n",
            "Fetching data for article 450/1000: User:MargotAlba\n",
            "Fetching data for article 451/1000: Talk:Tabqa Dam\n",
            "Fetching data for article 452/1000: User talk:103.230.106.9\n",
            "Fetching data for article 453/1000: User:Olando/monobook.js\n",
            "Fetching data for article 454/1000: User:Shamrez Mansoor\n",
            "Fetching data for article 455/1000: MELD\n",
            "Fetching data for article 456/1000: User talk:93.103.42.188\n",
            "Fetching data for article 457/1000: User talk:MrPeabodyEnergy\n",
            "Fetching data for article 458/1000: User talk:68.199.240.172\n",
            "Fetching data for article 459/1000: Category:April 2018 events in Russia\n",
            "Fetching data for article 460/1000: Category:1933\n",
            "Fetching data for article 461/1000: Kristi Haskins Johnson\n",
            "Fetching data for article 462/1000: User talk:Fluffycloudss\n",
            "Fetching data for article 463/1000: User talk:169.204.100.245\n",
            "Fetching data for article 464/1000: User talk:98.23.130.181\n",
            "Fetching data for article 465/1000: User talk:Sparkcomms\n",
            "Fetching data for article 466/1000: Talk:Weber (surname)\n",
            "Fetching data for article 467/1000: User talk:Bipolish\n",
            "Fetching data for article 468/1000: User:Bradrules/Userboxes/Saint Mary's College of California\n",
            "Fetching data for article 469/1000: Talk:Hmong people/Archive 1\n",
            "Fetching data for article 470/1000: Talk:Pipa snethlageae\n",
            "Fetching data for article 471/1000: User talk:LimzyKebasBung\n",
            "Fetching data for article 472/1000: Talk:Paul Sieveking\n",
            "Fetching data for article 473/1000: Template talk:RussiaBasicLawRef/kos\n",
            "Fetching data for article 474/1000: Portal:Latvia/Featured picture/48\n",
            "Fetching data for article 475/1000: Talk:Alakol\n",
            "Fetching data for article 476/1000: Abaristophora\n",
            "Fetching data for article 477/1000: Talk:Cannonball's Sharpshooters\n",
            "Fetching data for article 478/1000: User talk:72.196.223.114\n",
            "Fetching data for article 479/1000: User:Khaleefate\n",
            "Fetching data for article 480/1000: User talk:Aaaaa1234567890\n",
            "Fetching data for article 481/1000: Talk:Bromyl fluoride\n",
            "Fetching data for article 482/1000: User talk:84.92.88.191\n",
            "Fetching data for article 483/1000: Park ship\n",
            "Fetching data for article 484/1000: User talk:Marcanthony2004\n",
            "Fetching data for article 485/1000: User talk:82.18.78.26\n",
            "Fetching data for article 486/1000: User talk:223.25.60.149\n",
            "Fetching data for article 487/1000: Blind Alley (disambiguation)\n",
            "Fetching data for article 488/1000: Talk:Jean Six\n",
            "Fetching data for article 489/1000: Talk:Adam Black (rugby union)\n",
            "Fetching data for article 490/1000: User talk:Sapvdjksaazzd\n",
            "Fetching data for article 491/1000: Monic Cecconi-Botella\n",
            "Fetching data for article 492/1000: User talk:71.242.243.21\n",
            "Fetching data for article 493/1000: User talk:75.17.149.253\n",
            "Fetching data for article 494/1000: User:Jesusandmecm\n",
            "Fetching data for article 495/1000: User talk:69.114.88.120\n",
            "Fetching data for article 496/1000: Talk:Armor Alley\n",
            "Fetching data for article 497/1000: Blood Noir\n",
            "Fetching data for article 498/1000: User talk:99.62.119.85\n",
            "Fetching data for article 499/1000: User talk:Ranger14400\n",
            "Fetching data for article 500/1000: User:130.17.62.181\n",
            "Data collection complete. Saved to wikipedia_articles_data.csv\n"
          ]
        }
      ],
      "source": [
        "# write your answer here\n",
        "import requests\n",
        "import pandas as pd\n",
        "\n",
        "# API endpoint\n",
        "WIKI_API_ENDPOINT = \"https://en.wikipedia.org/w/api.php\"\n",
        "\n",
        "def fetch_article_metadata(title):\n",
        "    params = {\n",
        "        'action': 'query',\n",
        "        'prop': 'info',\n",
        "        'titles': title,\n",
        "        'format': 'json'\n",
        "    }\n",
        "    response = requests.get(WIKI_API_ENDPOINT, params=params)\n",
        "    data = response.json()\n",
        "    pages = data['query']['pages']\n",
        "    for page_id, page_info in pages.items():\n",
        "        if page_id != '-1':  # Check if the page exists\n",
        "            return {\n",
        "                'title': page_info['title'],\n",
        "                'pageid': page_id,\n",
        "                'ns': page_info['ns'],\n",
        "                'lastrevid': page_info['lastrevid'],\n",
        "                'touched': page_info['touched'],\n",
        "                'url': f\"https://en.wikipedia.org/wiki/{page_info['title']}\"\n",
        "            }\n",
        "    return None\n",
        "\n",
        "def fetch_edit_history(title):\n",
        "    params = {\n",
        "        'action': 'query',\n",
        "        'prop': 'revisions',\n",
        "        'titles': title,\n",
        "        'rvprop': 'timestamp|user|comment',\n",
        "        'rvlimit': 'max',\n",
        "        'format': 'json'\n",
        "    }\n",
        "    response = requests.get(WIKI_API_ENDPOINT, params=params)\n",
        "    data = response.json()\n",
        "    pages = data['query']['pages']\n",
        "    for page_id, page_info in pages.items():\n",
        "        if page_id != '-1':\n",
        "            revisions = page_info.get('revisions', [])\n",
        "            return [{\n",
        "                'timestamp': rev['timestamp'],\n",
        "                'user': rev.get('user', 'Anonymous'),\n",
        "                'comment': rev.get('comment', '')\n",
        "            } for rev in revisions]\n",
        "    return []\n",
        "\n",
        "def fetch_article_titles(num_titles):\n",
        "    titles = []\n",
        "    params = {\n",
        "        'action': 'query',\n",
        "        'list': 'random',\n",
        "        'rnlimit': num_titles,\n",
        "        'format': 'json'\n",
        "    }\n",
        "    response = requests.get(WIKI_API_ENDPOINT, params=params)\n",
        "    data = response.json()\n",
        "    random_pages = data['query']['random']\n",
        "    for page in random_pages:\n",
        "        titles.append(page['title'])\n",
        "    return titles\n",
        "\n",
        "def collect_data(num_samples):\n",
        "    titles = fetch_article_titles(num_samples)\n",
        "    collected_data = []\n",
        "\n",
        "    for i, title in enumerate(titles):\n",
        "        print(f\"Fetching data for article {i+1}/{num_samples}: {title}\")\n",
        "\n",
        "        metadata = fetch_article_metadata(title)\n",
        "        if metadata:\n",
        "            edit_history = fetch_edit_history(title)\n",
        "            collected_data.append({\n",
        "                **metadata,\n",
        "                'edit_history': edit_history\n",
        "            })\n",
        "\n",
        "    return collected_data\n",
        "\n",
        "# Collect 1000 samples\n",
        "data = collect_data(1000)\n",
        "\n",
        "# Save to CSV\n",
        "df = pd.DataFrame(data)\n",
        "df.to_csv('wikipedia_articles_data.csv', index=False)\n",
        "\n",
        "print(\"Data collection complete. Saved to wikipedia_articles_data.csv\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03jb4GZsBkBS"
      },
      "source": [
        "## Question 3 (10 Points)\n",
        "Write Python code to collect 1000 articles from Google Scholar (https://scholar.google.com/), Microsoft Academic (https://academic.microsoft.com/home), or CiteSeerX (https://citeseerx.ist.psu.edu/index), or Semantic Scholar (https://www.semanticscholar.org/), or ACM Digital Libraries (https://dl.acm.org/) with the keyword \"XYZ\". The articles should be published in the last 10 years (2014-2024).\n",
        "\n",
        "The following information from the article needs to be collected:\n",
        "\n",
        "(1) Title of the article\n",
        "\n",
        "(2) Venue/journal/conference being published\n",
        "\n",
        "(3) Year\n",
        "\n",
        "(4) Authors\n",
        "\n",
        "(5) Abstract"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YaGLbSHHB8Ej",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4fb29e1-0af9-4de0-9479-dab179c7564b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetching data for papers 1/1000...\n",
            "Fetching data for papers 101/1000...\n",
            "Failed to retrieve data: Status code 429\n",
            "No more papers or failed request. Exiting.\n",
            "Data collection complete. Retrieved 100 papers. Saved to semantic_scholar_articles.csv.\n"
          ]
        }
      ],
      "source": [
        "# write your answer here\n",
        "import requests\n",
        "import time\n",
        "import pandas as pd\n",
        "\n",
        "BASE_URL = 'https://api.semanticscholar.org/graph/v1/paper/search'\n",
        "\n",
        "\n",
        "PARAMS = {\n",
        "    'query': 'XYZ',\n",
        "    'limit': 100,\n",
        "    'year': '2014-2024',\n",
        "    'fields': 'title,venue,year,authors,abstract',\n",
        "}\n",
        "\n",
        "def fetch_papers(offset):\n",
        "    response = requests.get(BASE_URL, params={**PARAMS, 'offset': offset})\n",
        "    if response.status_code == 200:\n",
        "        return response.json()\n",
        "    else:\n",
        "        print(f\"Failed to retrieve data: Status code {response.status_code}\")\n",
        "        return None\n",
        "\n",
        "def parse_papers(papers):\n",
        "    paper_list = []\n",
        "    for paper in papers:\n",
        "        title = paper.get('title', 'N/A')\n",
        "        venue = paper.get('venue', 'N/A')\n",
        "        year = paper.get('year', 'N/A')\n",
        "        authors = ', '.join([author.get('name', 'N/A') for author in paper.get('authors', [])])\n",
        "        abstract = paper.get('abstract', 'N/A')\n",
        "        paper_list.append([title, venue, year, authors, abstract])\n",
        "    return paper_list\n",
        "\n",
        "all_papers = []\n",
        "total_papers = 1000\n",
        "offset = 0\n",
        "papers_per_request = 100\n",
        "\n",
        "while len(all_papers) < total_papers:\n",
        "    print(f\"Fetching data for papers {offset + 1}/{total_papers}...\")\n",
        "    data = fetch_papers(offset)\n",
        "    if data and 'data' in data:\n",
        "        papers = parse_papers(data['data'])\n",
        "        all_papers.extend(papers)\n",
        "        offset += papers_per_request\n",
        "        time.sleep(2)\n",
        "    else:\n",
        "        print(\"No more papers or failed request. Exiting.\")\n",
        "        break\n",
        "\n",
        "df = pd.DataFrame(all_papers, columns=['Title', 'Venue', 'Year', 'Authors', 'Abstract'])\n",
        "df.to_csv('semantic_scholar_articles.csv', index=False)\n",
        "\n",
        "print(f\"Data collection complete. Retrieved {len(all_papers)} papers. Saved to semantic_scholar_articles.csv.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJDe71iLB616"
      },
      "source": [
        "## Question 4A (10 Points)\n",
        "Develop Python code to collect data from social media platforms like Reddit, Instagram, Twitter (formerly known as X), Facebook, or any other. Use hashtags, keywords, usernames, or user IDs to gather the data.\n",
        "\n",
        "\n",
        "\n",
        "Ensure that the collected data has more than four columns.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MtKskTzbCLaU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8e1a23e-a9c5-4727-c90e-b3e59e064871"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data collection complete. Saved to reddit_posts_data.csv\n"
          ]
        }
      ],
      "source": [
        "# write your answer here\n",
        "import praw\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "def initialize_reddit_client():\n",
        "    return praw.Reddit(\n",
        "        client_id='LS_EEfvq6w66WD51xWNT0Q',\n",
        "        client_secret='X8mI-m5QoRVdsb3E92J4T0fzZvXDHg',\n",
        "        user_agent='v1.0'\n",
        "    )\n",
        "\n",
        "def fetch_reddit_data(keyword, num_posts, start_year, end_year):\n",
        "    reddit = initialize_reddit_client()\n",
        "    collected_data = []\n",
        "\n",
        "    for submission in reddit.subreddit('all').search(keyword, sort='new', limit=num_posts):\n",
        "        try:\n",
        "            title = submission.title\n",
        "            author = submission.author.name if submission.author else 'N/A'\n",
        "            post_url = submission.url\n",
        "            upvotes = submission.score\n",
        "            date = submission.created_utc\n",
        "            year = time.strftime('%Y', time.gmtime(date))\n",
        "\n",
        "            if start_year <= int(year) <= end_year:\n",
        "                collected_data.append({\n",
        "                    'Title': title,\n",
        "                    'Author': author,\n",
        "                    'Post URL': post_url,\n",
        "                    'Upvotes': upvotes,\n",
        "                    'Date': year\n",
        "                })\n",
        "\n",
        "            if len(collected_data) >= num_posts:\n",
        "                break\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing post: {e}\")\n",
        "\n",
        "    return collected_data\n",
        "\n",
        "# Fetch 50 posts with the keyword \"Python\"\n",
        "posts = fetch_reddit_data(keyword=\"Python\", num_posts=50, start_year=2014, end_year=2024)\n",
        "\n",
        "if posts:\n",
        "    df = pd.DataFrame(posts)\n",
        "    df.to_csv('reddit_posts_data.csv', index=False)\n",
        "    print(\"Data collection complete. Saved to reddit_posts_data.csv\")\n",
        "else:\n",
        "    print(\"No data collected. Please check the scraping process and response.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55W9AMdXCSpV"
      },
      "source": [
        "## Question 4B (10 Points)\n",
        "If you encounter challenges with Question-4 web scraping using Python, employ any online tools such as ParseHub or Octoparse for data extraction. Introduce the selected tool, outline the steps for web scraping, and showcase the final output in formats like CSV or Excel.\n",
        "\n",
        "\n",
        "\n",
        "Upload a document (Word or PDF File) in any shared storage (preferably UNT OneDrive) and add the publicly accessible link in the below code cell.\n",
        "\n",
        "Please only choose one option for question 4. If you do both options, we will grade only the first one"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I57NXsauCec2"
      },
      "outputs": [],
      "source": [
        "# write your answer here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZOhks1dXWEe"
      },
      "source": [
        "# Mandatory Question"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eqmHVEwaWhbV"
      },
      "source": [
        "**Important: Reflective Feedback on Web Scraping and Data Collection**\n",
        "\n",
        "\n",
        "\n",
        "Please share your thoughts and feedback on the web scraping and data collection exercises you have completed in this assignment. Consider the following points in your response:\n",
        "\n",
        "\n",
        "\n",
        "Learning Experience: Describe your overall learning experience in working on web scraping tasks. What were the key concepts or techniques you found most beneficial in understanding the process of extracting data from various online sources?\n",
        "\n",
        "\n",
        "\n",
        "Challenges Encountered: Were there specific difficulties in collecting data from certain websites, and how did you overcome them? If you opted for the non-coding option, share your experience with the chosen tool.\n",
        "\n",
        "\n",
        "\n",
        "Relevance to Your Field of Study: How might the ability to gather and analyze data from online sources enhance your work or research?\n",
        "\n",
        "**(no grading of your submission if this question is left unanswered)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "akAVJn9YBTQT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "4d8a6ead-f352-4dfa-c739-242f46dfdca3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nThe experience of completing web scraping projects has been quite helpful as it has helped me in gaining further insights of API’s, data extraction and dealing with rate limits. Some of them were parsing of web pages using BeautifulSoup and handling the APIs with retry mechanisms. As some of the challenges, there were rate limits and dynamic content which changed the tactics and strong error handling was necessary. This makes it easier to gather and assess data from online sources in a real-time manner, thus accurate and all inclusive data, and hence a boost in the quality and depth of my research.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "'''\n",
        "The experience of completing web scraping projects has been quite helpful as it has helped me in gaining further insights of API’s, data extraction and dealing with rate limits. Some of them were parsing of web pages using BeautifulSoup and handling the APIs with retry mechanisms. As some of the challenges, there were rate limits and dynamic content which changed the tactics and strong error handling was necessary. This makes it easier to gather and assess data from online sources in a real-time manner, thus accurate and all inclusive data, and hence a boost in the quality and depth of my research.\n",
        "'''"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "55W9AMdXCSpV"
      ],
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}