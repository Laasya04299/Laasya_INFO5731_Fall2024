{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ryk8D1Q4Wsrp"
      },
      "source": [
        "# **INFO5731 Assignment 2**\n",
        "\n",
        "In this assignment, you will work on gathering text data from an open data source via web scraping or API. Following this, you will need to clean the text data and perform syntactic analysis on the data. Follow the instructions carefully and design well-structured Python programs to address each question.\n",
        "\n",
        "**Expectations**:\n",
        "*   Use the provided .*ipynb* document to write your code & respond to the questions. Avoid generating a new file.\n",
        "*   Write complete answers and run all the cells before submission.\n",
        "*   Make sure the submission is \"clean\"; *i.e.*, no unnecessary code cells.\n",
        "*   Once finished, allow shared rights from top right corner (*see Canvas for details*).\n",
        "\n",
        "* **Make sure to submit the cleaned data CSV in the comment section - 10 points**\n",
        "\n",
        "**Total points**: 100\n",
        "\n",
        "**Deadline**: Tuesday, at 11:59 PM.\n",
        "\n",
        "**Late Submission will have a penalty of 10% reduction for each day after the deadline.**\n",
        "\n",
        "**Please check that the link you submitted can be opened and points to the correct assignment.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JkzR8cFAyGik"
      },
      "source": [
        "# Question 1 (40 points)\n",
        "\n",
        "Write a python program to collect text data from **either of the following sources** and save the data into a **csv file:**\n",
        "\n",
        "(1) Collect all the customer reviews of a product (you can choose any porduct) on amazon. [atleast 1000 reviews]\n",
        "\n",
        "(2) Collect the top 1000 User Reviews of a movie recently in 2023 or 2024 (you can choose any movie) from IMDB. [If one movie doesn't have sufficient reviews, collect reviews of atleast 2 or 3 movies]\n",
        "\n",
        "(3) Collect all the reviews of the top 1000 most popular software from G2 or Capterra.\n",
        "\n",
        "(4) Collect the **abstracts** of the top 10000 research papers by using the query \"machine learning\", \"data science\", \"artifical intelligence\", or \"information extraction\" from Semantic Scholar.\n",
        "\n",
        "(5) Collect all the information of the 904 narrators in the Densho Digital Repository.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Installing packages\n",
        "!pip install requests beautifulsoup4 pandas\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "# Function to fetch page content from IMDB\n",
        "def fetch_imdb_page(url):\n",
        "    headers = {\n",
        "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.93 Safari/537.36\"\n",
        "    }\n",
        "    response = requests.get(url, headers=headers)\n",
        "    if response.status_code != 200:\n",
        "        print(\"Failed to retrieve page.\")\n",
        "        return None\n",
        "    return response.content\n",
        "\n",
        "# Extracting user reviews from IMDB\n",
        "def extract_imdb_reviews(content):\n",
        "    soup = BeautifulSoup(content, 'html.parser')\n",
        "    review_elements = soup.find_all('div', class_='review-container')\n",
        "    reviews = []\n",
        "\n",
        "    for review in review_elements:\n",
        "        try:\n",
        "            title = review.find('a', class_='title')\n",
        "            rating = review.find('span', class_='rating-other-user-rating')\n",
        "            body = review.find('div', class_='text show-more__control')\n",
        "\n",
        "            title_text = title.text.strip() if title else \"No Title\"\n",
        "            rating_text = rating.text.strip() if rating else \"No Rating\"\n",
        "            body_text = body.text.strip() if body else \"No Review\"\n",
        "\n",
        "            reviews.append({\n",
        "                'Title': title_text,\n",
        "                'Rating': rating_text,\n",
        "                'Review': body_text\n",
        "            })\n",
        "        except Exception as e:\n",
        "            print(f\"Error while processing a review: {e}\")\n",
        "\n",
        "    return reviews\n",
        "\n",
        "# Function to collect user reviews from multiple IMDB movie URLs\n",
        "def collect_imdb_reviews(movie_urls, target_reviews=1000):\n",
        "    all_reviews = []\n",
        "\n",
        "    for url in movie_urls:\n",
        "        print(f\"Collecting reviews from {url}...\")\n",
        "        page_content = fetch_imdb_page(url)\n",
        "        if page_content is None:\n",
        "            continue\n",
        "\n",
        "        reviews_on_page = extract_imdb_reviews(page_content)\n",
        "        all_reviews.extend(reviews_on_page)\n",
        "\n",
        "        if len(all_reviews) >= target_reviews:\n",
        "            break\n",
        "\n",
        "    return all_reviews[:target_reviews]\n",
        "\n",
        "# List of movie URLs in 2023, 2024)\n",
        "imdb_movie_urls = [\n",
        "    \"https://www.imdb.com/title/tt15435876/reviews/?ref_=ttrt_sa_3\",\n",
        "    \"https://www.imdb.com/title/tt0412142/reviews/?ref_=ttrt_ql_2\",\n",
        "]\n",
        "\n",
        "# Collecting reviews from IMDB\n",
        "imdb_reviews = collect_imdb_reviews(imdb_movie_urls, target_reviews=1000)\n",
        "\n",
        "# Creating a DataFrame and save the reviews to a CSV file\n",
        "imdb_reviews_df = pd.DataFrame(imdb_reviews)\n",
        "imdb_reviews_df.to_csv('imdb_reviews.csv', index=False)\n",
        "\n",
        "# Displaying the first few rows of the DataFrame\n",
        "print(imdb_reviews_df.head())\n",
        "print(f\"Total reviews collected: {len(imdb_reviews_df)}. Saved to 'imdb_reviews.csv'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "frl3zHCR5Hut",
        "outputId": "5449fbeb-5ce5-432b-b659-a6389a06f800"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.32.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.12.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.8.30)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.6)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Collecting reviews from https://www.imdb.com/title/tt15435876/reviews/?ref_=ttrt_sa_3...\n",
            "Collecting reviews from https://www.imdb.com/title/tt0412142/reviews/?ref_=ttrt_ql_2...\n",
            "                                               Title Rating  \\\n",
            "0                           Wow...this was terrific!   9/10   \n",
            "1                                    Fantastic Start  10/10   \n",
            "2                                     So Far So Good   8/10   \n",
            "3  The Penguin continues the grimy and bleak Goth...   9/10   \n",
            "4  A gritty, violent crime drama that is so fun t...   9/10   \n",
            "\n",
            "                                              Review  \n",
            "0  Wow. The Penguin is just terrific. Everyone kn...  \n",
            "1  Absolutely nailed the tone and atmosphere. Gri...  \n",
            "2  The first episode is a direct continuation of ...  \n",
            "3  The Batman, for my taste had simply the greate...  \n",
            "4  I've been waiting for The Penguin ever since i...  \n",
            "Total reviews collected: 50. Saved to 'imdb_reviews.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90_NR8c5XGWc"
      },
      "source": [
        "# Question 2 (30 points)\n",
        "\n",
        "Write a python program to **clean the text data** you collected in the previous question and save the clean data in a new column in the csv file. The data cleaning steps include: [Code and output is required for each part]\n",
        "\n",
        "(1) Remove noise, such as special characters and punctuations.\n",
        "\n",
        "(2) Remove numbers.\n",
        "\n",
        "(3) Remove stopwords by using the stopwords list.\n",
        "\n",
        "(4) Lowercase all texts\n",
        "\n",
        "(5) Stemming.\n",
        "\n",
        "(6) Lemmatization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5QX6bJjGWXY9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "outputId": "6145398b-be4b-4bfa-a860-d35750e14b61"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.5)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              Review  \\\n",
              "0  Wow. The Penguin is just terrific. Everyone kn...   \n",
              "1  Absolutely nailed the tone and atmosphere. Gri...   \n",
              "2  The first episode is a direct continuation of ...   \n",
              "3  The Batman, for my taste had simply the greate...   \n",
              "4  I've been waiting for The Penguin ever since i...   \n",
              "\n",
              "                                      Cleaned_Review  \\\n",
              "0  wow penguin terrific everyone knows great acto...   \n",
              "1  absolutely nailed tone atmosphere gritty grimy...   \n",
              "2  first episode direct continuation matt reeves ...   \n",
              "3  batman taste simply greatest portrayal gotham ...   \n",
              "4  ive waiting penguin ever since first announced...   \n",
              "\n",
              "                                      Stemmed_Review  \\\n",
              "0  wow penguin terrif everyon know great actor co...   \n",
              "1  absolut nail tone atmospher gritti grimi dark ...   \n",
              "2  first episod direct continu matt reev batman i...   \n",
              "3  batman tast simpli greatest portray gotham cit...   \n",
              "4  ive wait penguin ever sinc first announc go se...   \n",
              "\n",
              "                                   Lemmatized_Review  \n",
              "0  wow penguin terrific everyone know great actor...  \n",
              "1  absolutely nailed tone atmosphere gritty grimy...  \n",
              "2  first episode direct continuation matt reef ba...  \n",
              "3  batman taste simply greatest portrayal gotham ...  \n",
              "4  ive waiting penguin ever since first announced...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e96f3c15-d774-4c23-8c3b-5e0253c56e21\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Review</th>\n",
              "      <th>Cleaned_Review</th>\n",
              "      <th>Stemmed_Review</th>\n",
              "      <th>Lemmatized_Review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Wow. The Penguin is just terrific. Everyone kn...</td>\n",
              "      <td>wow penguin terrific everyone knows great acto...</td>\n",
              "      <td>wow penguin terrif everyon know great actor co...</td>\n",
              "      <td>wow penguin terrific everyone know great actor...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Absolutely nailed the tone and atmosphere. Gri...</td>\n",
              "      <td>absolutely nailed tone atmosphere gritty grimy...</td>\n",
              "      <td>absolut nail tone atmospher gritti grimi dark ...</td>\n",
              "      <td>absolutely nailed tone atmosphere gritty grimy...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The first episode is a direct continuation of ...</td>\n",
              "      <td>first episode direct continuation matt reeves ...</td>\n",
              "      <td>first episod direct continu matt reev batman i...</td>\n",
              "      <td>first episode direct continuation matt reef ba...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The Batman, for my taste had simply the greate...</td>\n",
              "      <td>batman taste simply greatest portrayal gotham ...</td>\n",
              "      <td>batman tast simpli greatest portray gotham cit...</td>\n",
              "      <td>batman taste simply greatest portrayal gotham ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I've been waiting for The Penguin ever since i...</td>\n",
              "      <td>ive waiting penguin ever since first announced...</td>\n",
              "      <td>ive wait penguin ever sinc first announc go se...</td>\n",
              "      <td>ive waiting penguin ever since first announced...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e96f3c15-d774-4c23-8c3b-5e0253c56e21')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e96f3c15-d774-4c23-8c3b-5e0253c56e21 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e96f3c15-d774-4c23-8c3b-5e0253c56e21');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f5268c52-8473-4903-a27d-6f1ea799dbbd\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f5268c52-8473-4903-a27d-6f1ea799dbbd')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f5268c52-8473-4903-a27d-6f1ea799dbbd button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df[['Review', 'Cleaned_Review', 'Stemmed_Review', 'Lemmatized_Review']]\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Review\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Absolutely nailed the tone and atmosphere. Gritty and grimy and dark, but Farrell is able to capture that glimmer of charm Gandolfini's Tony Soprano did.There are similarities to the sopranos especially in tone. A lot of dark stuff goes down in this opening episode, but there's still comedic moments that match the tone and don't undermine it.Where to start with Farrell. Amazing is the right word. Love to see talented star actors go all in on roles like this, and the makeup/cgi or whatever exactly they did with transforming him into the penguin physically not only passes the eye test, it looks incredible realistic. There is always the risk that if the make up job isn't good enough or is just a little off, it can completely distract. In the penguin, it adds to his performance and the overall quality of the show because it's such a damn good job. And Farrell as an actor is completely immersed in this role. I'm maybe a little biased because he is one of my favorite actors prior to this show, but I think this is going to get him well-deserved accolades.I never really tune into new shows right away because I like to watch the episodes all at once, but I wanted to see how this one actually came out.Didn't disappoint, in fact blew me away. Kudos to everyone involved with this project.\",\n          \"I've been waiting for The Penguin ever since it was first announced it was going to series and I can tell you it's every bit as good as I expected. Colin Farrell is absolutely terrific as Oz Cobb a.k.a. The Penguin. He was a standout on The Batman and is even better in a lead role. On top of that Cristin Milioti is just as good as Sofia Falcone. The two of them fight to see who is the #1 gangster in Gotham and to \\\"bring order in all the chaos.\\\" Some people were worried that a supporting character like The Penguin couldn't carry a show and it wouldn't work not having Batman or Bruce Wayne but fear not because this is more than just villain character on a superhero show, it's a great crime drama on its own. It's a gritty, violent crime drama that's so fun to watch unfold. I hope we get more stories like this from this world.\",\n          \"The first episode is a direct continuation of Matt Reeves' The Batman and I imagine those who haven't seen the latter will be a bit lost. But I watched The Batman a while ago and this show did an admirable job of quickly re-familiarizing me with where the movie left off, and without getting bogged down in a didactic recap. It also recaptures the movie's aesthetic and grim tone nicely, although the show has a lot more moments of sly levity than the movie did.As in The Batman, Colin Farrell does an excellent job portraying The Penguin as a stereotypical mafia \\\"street guy:\\\" uncouth, profane, mercurial and quick to violence; but also savvy, cunning and able to read people. The character might have absolutely nothing to do with the comic book version but he's interesting in his own right.I have my doubts about the show giving The Penguin at teenage sidekick; and I don't know if The Penguin's machinations will be enough to sustain a whole season. But so far it's off to a great start.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Cleaned_Review\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"absolutely nailed tone atmosphere gritty grimy dark farrell able capture glimmer charm gandolfinis tony soprano didthere similarities sopranos especially tone lot dark stuff goes opening episode theres still comedic moments match tone dont undermine itwhere start farrell amazing right word love see talented star actors go roles like makeupcgi whatever exactly transforming penguin physically passes eye test looks incredible realistic always risk make job isnt good enough little completely distract penguin adds performance overall quality show damn good job farrell actor completely immersed role im maybe little biased one favorite actors prior show think going get welldeserved accoladesi never really tune new shows right away like watch episodes wanted see one actually came outdidnt disappoint fact blew away kudos everyone involved project\",\n          \"ive waiting penguin ever since first announced going series tell every bit good expected colin farrell absolutely terrific oz cobb aka penguin standout batman even better lead role top cristin milioti good sofia falcone two fight see gangster gotham bring order chaos people worried supporting character like penguin couldnt carry show wouldnt work batman bruce wayne fear villain character superhero show great crime drama gritty violent crime drama thats fun watch unfold hope get stories like world\",\n          \"first episode direct continuation matt reeves batman imagine havent seen latter bit lost watched batman ago show admirable job quickly refamiliarizing movie left without getting bogged didactic recap also recaptures movies aesthetic grim tone nicely although show lot moments sly levity movie didas batman colin farrell excellent job portraying penguin stereotypical mafia street guy uncouth profane mercurial quick violence also savvy cunning able read people character might absolutely nothing comic book version hes interesting righti doubts show giving penguin teenage sidekick dont know penguins machinations enough sustain whole season far great start\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Stemmed_Review\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"absolut nail tone atmospher gritti grimi dark farrel abl captur glimmer charm gandolfini toni soprano didther similar soprano especi tone lot dark stuff goe open episod there still comed moment match tone dont undermin itwher start farrel amaz right word love see talent star actor go role like makeupcgi whatev exactli transform penguin physic pass eye test look incred realist alway risk make job isnt good enough littl complet distract penguin add perform overal qualiti show damn good job farrel actor complet immers role im mayb littl bias one favorit actor prior show think go get welldeserv accoladesi never realli tune new show right away like watch episod want see one actual came outdidnt disappoint fact blew away kudo everyon involv project\",\n          \"ive wait penguin ever sinc first announc go seri tell everi bit good expect colin farrel absolut terrif oz cobb aka penguin standout batman even better lead role top cristin milioti good sofia falcon two fight see gangster gotham bring order chao peopl worri support charact like penguin couldnt carri show wouldnt work batman bruce wayn fear villain charact superhero show great crime drama gritti violent crime drama that fun watch unfold hope get stori like world\",\n          \"first episod direct continu matt reev batman imagin havent seen latter bit lost watch batman ago show admir job quickli refamiliar movi left without get bog didact recap also recaptur movi aesthet grim tone nice although show lot moment sli leviti movi dida batman colin farrel excel job portray penguin stereotyp mafia street guy uncouth profan mercuri quick violenc also savvi cun abl read peopl charact might absolut noth comic book version he interest righti doubt show give penguin teenag sidekick dont know penguin machin enough sustain whole season far great start\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Lemmatized_Review\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"absolutely nailed tone atmosphere gritty grimy dark farrell able capture glimmer charm gandolfinis tony soprano didthere similarity soprano especially tone lot dark stuff go opening episode there still comedic moment match tone dont undermine itwhere start farrell amazing right word love see talented star actor go role like makeupcgi whatever exactly transforming penguin physically pass eye test look incredible realistic always risk make job isnt good enough little completely distract penguin add performance overall quality show damn good job farrell actor completely immersed role im maybe little biased one favorite actor prior show think going get welldeserved accoladesi never really tune new show right away like watch episode wanted see one actually came outdidnt disappoint fact blew away kudos everyone involved project\",\n          \"ive waiting penguin ever since first announced going series tell every bit good expected colin farrell absolutely terrific oz cobb aka penguin standout batman even better lead role top cristin milioti good sofia falcone two fight see gangster gotham bring order chaos people worried supporting character like penguin couldnt carry show wouldnt work batman bruce wayne fear villain character superhero show great crime drama gritty violent crime drama thats fun watch unfold hope get story like world\",\n          \"first episode direct continuation matt reef batman imagine havent seen latter bit lost watched batman ago show admirable job quickly refamiliarizing movie left without getting bogged didactic recap also recapture movie aesthetic grim tone nicely although show lot moment sly levity movie didas batman colin farrell excellent job portraying penguin stereotypical mafia street guy uncouth profane mercurial quick violence also savvy cunning able read people character might absolutely nothing comic book version he interesting righti doubt show giving penguin teenage sidekick dont know penguin machination enough sustain whole season far great start\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "# Write code for each of the sub parts with proper comments.\n",
        "# Install necessary libraries\n",
        "!pip install nltk pandas\n",
        "\n",
        "import re\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "# Download NLTK data\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "# Load the data\n",
        "df = pd.read_csv('imdb_reviews.csv')\n",
        "\n",
        "# Function to remove special characters and punctuation\n",
        "remove_special_characters = lambda text: re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "\n",
        "# Function to remove numbers\n",
        "remove_numbers = lambda text: re.sub(r'\\d+', '', text)\n",
        "\n",
        "# Function to remove stopwords\n",
        "def remove_stopwords(text):\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    words = text.split()\n",
        "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
        "    return ' '.join(filtered_words)\n",
        "\n",
        "# Function to lowercase all text\n",
        "lowercase_text = lambda text: text.lower()\n",
        "\n",
        "# Function for stemming\n",
        "stem_text = lambda text: ' '.join([PorterStemmer().stem(word) for word in text.split()])\n",
        "\n",
        "# Function for lemmatization\n",
        "lemmatize_text = lambda text: ' '.join([WordNetLemmatizer().lemmatize(word) for word in text.split()])\n",
        "\n",
        "# Apply the cleaning functions step by step\n",
        "df['Cleaned_Review'] = df['Review'].apply(remove_special_characters)\n",
        "df['Cleaned_Review'] = df['Cleaned_Review'].apply(remove_numbers)\n",
        "df['Cleaned_Review'] = df['Cleaned_Review'].apply(remove_stopwords)\n",
        "df['Cleaned_Review'] = df['Cleaned_Review'].apply(lowercase_text)\n",
        "df['Stemmed_Review'] = df['Cleaned_Review'].apply(stem_text)\n",
        "df['Lemmatized_Review'] = df['Cleaned_Review'].apply(lemmatize_text)\n",
        "\n",
        "# Save the cleaned data to a new CSV file\n",
        "df.to_csv('cleaned_imdb_reviews.csv', index=False)\n",
        "\n",
        "# Display the first few rows of the cleaned data\n",
        "df[['Review', 'Cleaned_Review', 'Stemmed_Review', 'Lemmatized_Review']].head()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1F_PZdH9Sh49"
      },
      "source": [
        "# Question 3 (30 points)\n",
        "\n",
        "Write a python program to **conduct syntax and structure analysis of the clean text** you just saved above. The syntax and structure analysis includes:\n",
        "\n",
        "(1) **Parts of Speech (POS) Tagging:** Tag Parts of Speech of each word in the text, and calculate the total number of N(oun), V(erb), Adj(ective), Adv(erb), respectively.\n",
        "\n",
        "(2) **Constituency Parsing and Dependency Parsing:** print out the constituency parsing trees and dependency parsing trees of all the sentences. Using one sentence as an example to explain your understanding about the constituency parsing tree and dependency parsing tree.\n",
        "\n",
        "(3) **Named Entity Recognition:** Extract all the entities such as person names, organizations, locations, product names, and date from the clean texts, calculate the count of each entity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y0oOSlsOS0cq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64c6c3bd-f6c5-4fb4-937a-f536d65ea218"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.7.6)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.12.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.66.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.9.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (71.0.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (24.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.4.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.26.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.23.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.8.30)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.8.1)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.19.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (2.1.5)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.16.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "POS Tags for Sample Review: [('never', 'RB'), ('paid', 'VBN'), ('much', 'JJ'), ('attention', 'NN'), ('house', 'NN'), ('md', 'NN'), ('first', 'RB'), ('premiered', 'VBD'), ('heard', 'JJ'), ('couple', 'NN'), ('people', 'NNS'), ('basically', 'RB'), ('thing', 'NN'), ('every', 'DT'), ('episode', 'NN'), ('impossible', 'JJ'), ('disease', 'NN'), ('diagnose', 'JJ'), ('house', 'NN'), ('mess', 'NN'), ('team', 'NN'), ('house', 'NN'), ('suddenly', 'RB'), ('solves', 'VBZ'), ('casebut', 'JJ'), ('one', 'CD'), ('day', 'NN'), ('bored', 'VBD'), ('switched', 'JJ'), ('tv', 'NN'), ('house', 'NN'), ('happened', 'VBD'), ('season', 'NN'), ('finale', 'NN'), ('titled', 'VBD'), ('help', 'NN'), ('going', 'VBG'), ('honest', 'JJS'), ('blew', 'VB'), ('away', 'RB'), ('know', 'JJ'), ('happening', 'VBG'), ('character', 'NN'), ('point', 'NN'), ('story', 'NN'), ('acting', 'VBG'), ('fantastic', 'JJ'), ('atmosphere', 'RB'), ('superb', 'JJ'), ('complexity', 'NN'), ('dr', 'NN'), ('gregory', 'NN'), ('house', 'NN'), ('intrigued', 'VBD'), ('saw', 'JJ'), ('tragic', 'JJ'), ('hero', 'NN'), ('something', 'NN'), ('find', 'VBP'), ('work', 'NN'), ('literature', 'NN'), ('tragic', 'JJ'), ('flaw', 'NN'), ('leg', 'NN'), ('physical', 'JJ'), ('limitation', 'NN'), ('brought', 'VBD'), ('leg', 'JJR'), ('mental', 'JJ'), ('one', 'CD'), ('well', 'RB'), ('pain', 'JJ'), ('suffers', 'NNS'), ('day', 'NN'), ('day', 'NN'), ('lead', 'VB'), ('man', 'NN'), ('see', 'VBP'), ('house', 'NN'), ('assbut', 'NN'), ('feel', 'NN'), ('know', 'RB'), ('he', 'PRP'), ('as', 'IN'), ('also', 'RB'), ('hugh', 'IN'), ('laurie', 'RB'), ('good', 'JJ'), ('job', 'NN'), ('accent', 'NN'), ('watched', 'VBD'), ('bit', 'NN'), ('fry', 'JJ'), ('laurie', 'NN'), ('probably', 'RB'), ('never', 'RB'), ('would', 'MD'), ('guessed', 'VBD'), ('hugh', 'RB'), ('britishhouse', 'IN'), ('like', 'IN'), ('beautiful', 'JJ'), ('novel', 'JJ'), ('theme', 'NN'), ('episode', 'NN'), ('episode', 'NN'), ('overall', 'JJ'), ('theme', 'NN'), ('television', 'NN'), ('show', 'NN'), ('work', 'NN'), ('art', 'RB'), ('hate', 'VB'), ('many', 'JJ'), ('dismiss', 'JJ'), ('premise', 'NN'), ('hospital', 'NN'), ('watched', 'VBD'), ('every', 'DT'), ('episode', 'NN'), ('house', 'NN'), ('since', 'IN'), ('first', 'JJ'), ('saw', 'VBD'), ('many', 'JJ'), ('hour', 'NN'), ('well', 'RB'), ('spent', 'JJ'), ('youve', 'NN'), ('never', 'RB'), ('seen', 'VBN'), ('itthe', 'JJ'), ('complete', 'JJ'), ('series', 'NN'), ('dvd', 'NN')]\n",
            "Noun Count: 58, Verb Count: 21, Adjective Count: 29, Adverb Count: 16\n",
            "\n",
            "Dependency Parsing Tree:\n",
            "never -> neg (head: paid)\n",
            "paid -> ROOT (head: paid)\n",
            "much -> amod (head: house)\n",
            "attention -> compound (head: house)\n",
            "house -> dobj (head: paid)\n",
            "md -> nsubj (head: premiered)\n",
            "first -> advmod (head: premiered)\n",
            "premiered -> advcl (head: paid)\n",
            "heard -> dep (head: paid)\n",
            "couple -> compound (head: people)\n",
            "people -> nsubj (head: thing)\n",
            "basically -> advmod (head: thing)\n",
            "thing -> ccomp (head: heard)\n",
            "every -> det (head: house)\n",
            "episode -> nmod (head: disease)\n",
            "impossible -> amod (head: disease)\n",
            "disease -> compound (head: diagnose)\n",
            "diagnose -> compound (head: house)\n",
            "house -> compound (head: house)\n",
            "mess -> compound (head: team)\n",
            "team -> compound (head: house)\n",
            "house -> nsubj (head: solves)\n",
            "suddenly -> advmod (head: solves)\n",
            "solves -> conj (head: paid)\n",
            "casebut -> dobj (head: solves)\n",
            "one -> nummod (head: day)\n",
            "day -> npadvmod (head: bored)\n",
            "bored -> nsubj (head: switched)\n",
            "switched -> ccomp (head: solves)\n",
            "tv -> compound (head: house)\n",
            "house -> dobj (head: switched)\n",
            "happened -> amod (head: finale)\n",
            "season -> compound (head: finale)\n",
            "finale -> compound (head: help)\n",
            "titled -> acl (head: finale)\n",
            "help -> dobj (head: paid)\n",
            "going -> acl (head: help)\n",
            "honest -> acomp (head: going)\n",
            "blew -> advcl (head: paid)\n",
            "away -> prt (head: blew)\n",
            "know -> dep (head: paid)\n",
            "happening -> amod (head: story)\n",
            "character -> compound (head: point)\n",
            "point -> compound (head: story)\n",
            "story -> compound (head: house)\n",
            "acting -> amod (head: atmosphere)\n",
            "fantastic -> amod (head: atmosphere)\n",
            "atmosphere -> nmod (head: house)\n",
            "superb -> compound (head: complexity)\n",
            "complexity -> appos (head: atmosphere)\n",
            "dr -> compound (head: house)\n",
            "gregory -> compound (head: house)\n",
            "house -> compound (head: intrigued)\n",
            "intrigued -> nsubj (head: saw)\n",
            "saw -> dep (head: paid)\n",
            "tragic -> amod (head: hero)\n",
            "hero -> dobj (head: saw)\n",
            "something -> nsubj (head: find)\n",
            "find -> ccomp (head: saw)\n",
            "work -> compound (head: literature)\n",
            "literature -> dobj (head: find)\n",
            "tragic -> amod (head: limitation)\n",
            "flaw -> compound (head: limitation)\n",
            "leg -> nmod (head: limitation)\n",
            "physical -> amod (head: limitation)\n",
            "limitation -> nsubj (head: brought)\n",
            "brought -> conj (head: paid)\n",
            "leg -> dobj (head: brought)\n",
            "mental -> amod (head: suffers)\n",
            "one -> nummod (head: well)\n",
            "well -> intj (head: suffers)\n",
            "pain -> compound (head: suffers)\n",
            "suffers -> dobj (head: brought)\n",
            "day -> compound (head: day)\n",
            "day -> npadvmod (head: see)\n",
            "lead -> compound (head: man)\n",
            "man -> nsubj (head: see)\n",
            "see -> conj (head: brought)\n",
            "house -> dobj (head: see)\n",
            "assbut -> cc (head: see)\n",
            "feel -> conj (head: see)\n",
            "know -> xcomp (head: feel)\n",
            "he -> dobj (head: know)\n",
            "as -> prep (head: feel)\n",
            "also -> pcomp (head: as)\n",
            "hugh -> compound (head: accent)\n",
            "laurie -> compound (head: accent)\n",
            "good -> amod (head: accent)\n",
            "job -> compound (head: accent)\n",
            "accent -> nsubj (head: watched)\n",
            "watched -> conj (head: brought)\n",
            "bit -> compound (head: laurie)\n",
            "fry -> compound (head: laurie)\n",
            "laurie -> dobj (head: watched)\n",
            "probably -> advmod (head: guessed)\n",
            "never -> neg (head: guessed)\n",
            "would -> aux (head: guessed)\n",
            "guessed -> conj (head: paid)\n",
            "hugh -> compound (head: britishhouse)\n",
            "britishhouse -> dobj (head: guessed)\n",
            "like -> prep (head: britishhouse)\n",
            "beautiful -> amod (head: episode)\n",
            "novel -> amod (head: theme)\n",
            "theme -> compound (head: episode)\n",
            "episode -> compound (head: episode)\n",
            "episode -> nmod (head: art)\n",
            "overall -> amod (head: show)\n",
            "theme -> compound (head: television)\n",
            "television -> compound (head: show)\n",
            "show -> compound (head: art)\n",
            "work -> compound (head: art)\n",
            "art -> compound (head: hate)\n",
            "hate -> ccomp (head: guessed)\n",
            "many -> amod (head: hospital)\n",
            "dismiss -> compound (head: hospital)\n",
            "premise -> compound (head: hospital)\n",
            "hospital -> nsubj (head: watched)\n",
            "watched -> conj (head: paid)\n",
            "every -> det (head: house)\n",
            "episode -> compound (head: house)\n",
            "house -> dobj (head: watched)\n",
            "since -> mark (head: saw)\n",
            "first -> advmod (head: saw)\n",
            "saw -> advcl (head: watched)\n",
            "many -> amod (head: hour)\n",
            "hour -> npadvmod (head: spent)\n",
            "well -> advmod (head: spent)\n",
            "spent -> ccomp (head: saw)\n",
            "you -> nsubj (head: seen)\n",
            "ve -> aux (head: seen)\n",
            "never -> neg (head: seen)\n",
            "seen -> ccomp (head: saw)\n",
            "itthe -> det (head: series)\n",
            "complete -> amod (head: series)\n",
            "series -> dobj (head: seen)\n",
            "dvd -> npadvmod (head: seen)\n",
            "\n",
            "Mimicked Constituency Parsing Tree (token -> head relation):\n",
            "never -> paid\n",
            "paid -> paid\n",
            "much -> house\n",
            "attention -> house\n",
            "house -> paid\n",
            "md -> premiered\n",
            "first -> premiered\n",
            "premiered -> paid\n",
            "heard -> paid\n",
            "couple -> people\n",
            "people -> thing\n",
            "basically -> thing\n",
            "thing -> heard\n",
            "every -> house\n",
            "episode -> disease\n",
            "impossible -> disease\n",
            "disease -> diagnose\n",
            "diagnose -> house\n",
            "house -> house\n",
            "mess -> team\n",
            "team -> house\n",
            "house -> solves\n",
            "suddenly -> solves\n",
            "solves -> paid\n",
            "casebut -> solves\n",
            "one -> day\n",
            "day -> bored\n",
            "bored -> switched\n",
            "switched -> solves\n",
            "tv -> house\n",
            "house -> switched\n",
            "happened -> finale\n",
            "season -> finale\n",
            "finale -> help\n",
            "titled -> finale\n",
            "help -> paid\n",
            "going -> help\n",
            "honest -> going\n",
            "blew -> paid\n",
            "away -> blew\n",
            "know -> paid\n",
            "happening -> story\n",
            "character -> point\n",
            "point -> story\n",
            "story -> house\n",
            "acting -> atmosphere\n",
            "fantastic -> atmosphere\n",
            "atmosphere -> house\n",
            "superb -> complexity\n",
            "complexity -> atmosphere\n",
            "dr -> house\n",
            "gregory -> house\n",
            "house -> intrigued\n",
            "intrigued -> saw\n",
            "saw -> paid\n",
            "tragic -> hero\n",
            "hero -> saw\n",
            "something -> find\n",
            "find -> saw\n",
            "work -> literature\n",
            "literature -> find\n",
            "tragic -> limitation\n",
            "flaw -> limitation\n",
            "leg -> limitation\n",
            "physical -> limitation\n",
            "limitation -> brought\n",
            "brought -> paid\n",
            "leg -> brought\n",
            "mental -> suffers\n",
            "one -> well\n",
            "well -> suffers\n",
            "pain -> suffers\n",
            "suffers -> brought\n",
            "day -> day\n",
            "day -> see\n",
            "lead -> man\n",
            "man -> see\n",
            "see -> brought\n",
            "house -> see\n",
            "assbut -> see\n",
            "feel -> see\n",
            "know -> feel\n",
            "he -> know\n",
            "as -> feel\n",
            "also -> as\n",
            "hugh -> accent\n",
            "laurie -> accent\n",
            "good -> accent\n",
            "job -> accent\n",
            "accent -> watched\n",
            "watched -> brought\n",
            "bit -> laurie\n",
            "fry -> laurie\n",
            "laurie -> watched\n",
            "probably -> guessed\n",
            "never -> guessed\n",
            "would -> guessed\n",
            "guessed -> paid\n",
            "hugh -> britishhouse\n",
            "britishhouse -> guessed\n",
            "like -> britishhouse\n",
            "beautiful -> episode\n",
            "novel -> theme\n",
            "theme -> episode\n",
            "episode -> episode\n",
            "episode -> art\n",
            "overall -> show\n",
            "theme -> television\n",
            "television -> show\n",
            "show -> art\n",
            "work -> art\n",
            "art -> hate\n",
            "hate -> guessed\n",
            "many -> hospital\n",
            "dismiss -> hospital\n",
            "premise -> hospital\n",
            "hospital -> watched\n",
            "watched -> paid\n",
            "every -> house\n",
            "episode -> house\n",
            "house -> watched\n",
            "since -> saw\n",
            "first -> saw\n",
            "saw -> watched\n",
            "many -> hour\n",
            "hour -> spent\n",
            "well -> spent\n",
            "spent -> saw\n",
            "you -> seen\n",
            "ve -> seen\n",
            "never -> seen\n",
            "seen -> saw\n",
            "itthe -> series\n",
            "complete -> series\n",
            "series -> seen\n",
            "dvd -> seen\n",
            "\n",
            "Explanation of Dependency and Constituency Parsing:\n",
            "Token: This, Dependency: det, Head: movie\n",
            "Token: movie, Dependency: nsubj, Head: is\n",
            "Token: is, Dependency: ROOT, Head: is\n",
            "Token: very, Dependency: advmod, Head: interesting\n",
            "Token: interesting, Dependency: acomp, Head: is\n",
            "Token: ., Dependency: punct, Head: is\n",
            "\n",
            "Named Entity Count: Counter({'PERSON': 41, 'ORG': 17, 'CARDINAL': 15, 'DATE': 11, 'ORDINAL': 10, 'NORP': 9, 'GPE': 3, 'TIME': 2, 'EVENT': 1})\n",
            "\n",
            "Named Entities from Reviews:\n",
            "               Entity     Type\n",
            "0               first  ORDINAL\n",
            "1             one day     DATE\n",
            "2             day day     DATE\n",
            "3               first  ORDINAL\n",
            "4  around couple year     DATE\n"
          ]
        }
      ],
      "source": [
        "# Your code here\n",
        "# Libraries\n",
        "!pip install spacy\n",
        "!pip install nltk\n",
        "import spacy\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "import nltk\n",
        "from nltk import pos_tag\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "#  NLTK resources\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "# Load Spacy model for parsing and NER\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Load the cleaned text data\n",
        "df = pd.read_csv('cleaned_imdb_reviews.csv')\n",
        "\n",
        "# Selecting the first few cleaned reviews for analysis\n",
        "texts = df['Lemmatized_Review'].dropna().tolist()\n",
        "\n",
        "# (1) Parts of Speech (POS) Tagging and Counting\n",
        "def pos_tagging_and_count(text):\n",
        "    tokens = word_tokenize(text)\n",
        "    tagged = pos_tag(tokens)\n",
        "\n",
        "    # Counting Nouns, Verbs, Adjectives, and Adverbs\n",
        "    pos_counts = Counter(tag for word, tag in tagged)\n",
        "    noun_count = sum(1 for word, tag in tagged if tag.startswith('NN'))\n",
        "    verb_count = sum(1 for word, tag in tagged if tag.startswith('VB'))\n",
        "    adj_count = sum(1 for word, tag in tagged if tag.startswith('JJ'))\n",
        "    adv_count = sum(1 for word, tag in tagged if tag.startswith('RB'))\n",
        "\n",
        "    return tagged, noun_count, verb_count, adj_count, adv_count\n",
        "\n",
        "# Applying POS tagging to the first review\n",
        "sample_review = texts[0]\n",
        "pos_tags, noun_count, verb_count, adj_count, adv_count = pos_tagging_and_count(sample_review)\n",
        "\n",
        "print(f\"POS Tags for Sample Review: {pos_tags}\")\n",
        "print(f\"Noun Count: {noun_count}, Verb Count: {verb_count}, Adjective Count: {adj_count}, Adverb Count: {adv_count}\")\n",
        "\n",
        "# (2) Constituency Parsing and Dependency Parsing\n",
        "def print_parsing_analysis(text):\n",
        "    doc = nlp(text)\n",
        "\n",
        "    # Dependency Parsing Tree\n",
        "    print(\"\\nDependency Parsing Tree:\")\n",
        "    for token in doc:\n",
        "        print(f\"{token.text} -> {token.dep_} (head: {token.head.text})\")\n",
        "\n",
        "    # Constituency Parsing Tree (Spacy does not have built-in support)\n",
        "    # Displaying the tokens and their respective heads to mimic the structure\n",
        "    print(\"\\nMimicked Constituency Parsing Tree (token -> head relation):\")\n",
        "    for token in doc:\n",
        "        print(f\"{token.text} -> {token.head.text}\")\n",
        "\n",
        "# Applying parsing to the same review\n",
        "print_parsing_analysis(sample_review)\n",
        "\n",
        "# Explanation of Parsing (Using one sentence as a sample):\n",
        "sample_sentence = \"This movie is very interesting.\"\n",
        "doc_example = nlp(sample_sentence)\n",
        "\n",
        "print(\"\\nExplanation of Dependency and Constituency Parsing:\")\n",
        "for token in doc_example:\n",
        "    print(f\"Token: {token.text}, Dependency: {token.dep_}, Head: {token.head.text}\")\n",
        "\n",
        "# Constituency Parsing: Breaks the sentence into nested sub-phrases (noun phrase, verb phrase).\n",
        "# Dependency Parsing: Shows the syntactic structure where each word is linked to its head (governing word).\n",
        "\n",
        "# (3) Named Entity Recognition (NER)\n",
        "def named_entity_recognition(text):\n",
        "    doc = nlp(text)\n",
        "    entities = [(ent.text, ent.label_) for ent in doc.ents]\n",
        "    return entities\n",
        "\n",
        "# Extract Named Entities from all reviews\n",
        "all_entities = []\n",
        "for review in texts:\n",
        "    entities = named_entity_recognition(review)\n",
        "    all_entities.extend(entities)\n",
        "\n",
        "# Count occurrences of each entity type\n",
        "entity_counter = Counter([entity[1] for entity in all_entities])\n",
        "print(f\"\\nNamed Entity Count: {entity_counter}\")\n",
        "\n",
        "# Save the Named Entities and their counts to a CSV file\n",
        "entities_df = pd.DataFrame(all_entities, columns=['Entity', 'Type'])\n",
        "entities_df.to_csv('imdb_named_entities.csv', index=False)\n",
        "\n",
        "# Display the first few named entities\n",
        "print(\"\\nNamed Entities from Reviews:\")\n",
        "print(entities_df.head())\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Comment**\n",
        "Make sure to submit the cleaned data CSV in the comment section - 10 points"
      ],
      "metadata": {
        "id": "CXNn1lEVbMsv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('cleaned_imdb_reviews.csv')"
      ],
      "metadata": {
        "id": "qYRO5Cn8bYwZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "ec9c2fa3-79cd-437a-fe4f-eaf79b2be655"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_b7329adf-3d57-40a9-8043-0be5af574602\", \"cleaned_imdb_reviews.csv\", 151394)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mandatory Question\n",
        "\n",
        "Provide your thoughts on the assignment. What did you find challenging, and what aspects did you enjoy? Your opinion on the provided time to complete the assignment."
      ],
      "metadata": {
        "id": "q8BFCvWp32cf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "The assignment was really tasking, particularly the first part of data gathering. The reviews showed a lot of inconsistency\n",
        "for every time I run the code. At some point it produced 0 reviews at other time 25 or even 50. This was because of the\n",
        "fact that the website or may be my code could not allow scraping to take place for long. I feel that some of the website\n",
        "that were suggested like the Capterra and G2 had issues with allowing scaping. All in all. it was a very challenging assignment.\n",
        "but worth it. The time too was not very enough for a lot of exploration.\n",
        "'''"
      ],
      "metadata": {
        "id": "_e557s2w4BpK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "40366d30-81fa-47f3-d6f4-f7990afbe286"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nThe assignment was really tasking, particularly the first part of data gathering. The reviews showed a lot of inconsistency \\nfor every time I run the code. At some point it produced 0 reviews at other time 25 or even 50. This was because of the\\nfact that the website or may be my code could not allow scraping to take place for long. I feel that some of the website\\nthat were suggested like the Capterra and G2 had issues with allowing scaping. All in all. it was a very challenging assignment.\\nbut worth it. The time too was not very enough for a lot of exploration.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}